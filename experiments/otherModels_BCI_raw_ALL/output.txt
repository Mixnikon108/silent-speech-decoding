[DATASET] Loading dataset from: BCI_raw.npz
[data] Cargando datos del dataset BCI
[INFO] Cargando datos desde: /media/beegfs/home/w314/w314139/PROJECT/silent-speech-decoding/data/processed/BCI2020/BCI_raw.npz
[INFO] Aplicando z-score normalization por trial
    - Forma de entrada (esperada): (trials, canales, muestras) = torch.Size([4500, 64, 795])
    - Calculando media y desviación estándar por trial
    - Mean shape: torch.Size([4500, 1, 1]), Std shape: torch.Size([4500, 1, 1])
    - Normalización completada. Forma de salida: torch.Size([4500, 64, 795])
[INFO] Padding aplicado: se añaden 5 valores a la derecha (dim original: 795)
[INFO] Dimensión temporal final: 800
[INFO] Aplicando z-score normalization por trial
    - Forma de entrada (esperada): (trials, canales, muestras) = torch.Size([750, 64, 795])
    - Calculando media y desviación estándar por trial
    - Mean shape: torch.Size([750, 1, 1]), Std shape: torch.Size([750, 1, 1])
    - Normalización completada. Forma de salida: torch.Size([750, 64, 795])
[INFO] Padding aplicado: se añaden 5 valores a la derecha (dim original: 795)
[INFO] Dimensión temporal final: 800
[INFO] Aplicando z-score normalization por trial
    - Forma de entrada (esperada): (trials, canales, muestras) = torch.Size([750, 64, 795])
    - Calculando media y desviación estándar por trial
    - Mean shape: torch.Size([750, 1, 1]), Std shape: torch.Size([750, 1, 1])
    - Normalización completada. Forma de salida: torch.Size([750, 64, 795])
[INFO] Padding aplicado: se añaden 5 valores a la derecha (dim original: 795)
[INFO] Dimensión temporal final: 800
[INFO] Cargando datos de todos los sujetos (concatenados)
[INFO] Dimensiones finales:
    - X_train: torch.Size([4500, 64, 800]), y_train: torch.Size([4500])
    - X_val:   torch.Size([750, 64, 800]), y_val:   torch.Size([750])
    - X_test:  torch.Size([750, 64, 800]), y_test:  torch.Size([750])
[INFO] Creando DataLoaders:
    - Batch size (train): 64  | Shuffle: True
    - Batch size (eval) : 32  | Shuffle: False
[INFO] Número de batches:
    - Train: 71 batches
    - Val  : 24 batches
    - Test : 24 batches

▶ Entrenando mlp …
Epoch 010/100 – train acc: 0.227, val acc: 0.233
Epoch 020/100 – train acc: 0.223, val acc: 0.225
Epoch 030/100 – train acc: 0.231, val acc: 0.220
Epoch 040/100 – train acc: 0.234, val acc: 0.217
Epoch 050/100 – train acc: 0.224, val acc: 0.212
Epoch 060/100 – train acc: 0.219, val acc: 0.212
Epoch 070/100 – train acc: 0.215, val acc: 0.207
Epoch 080/100 – train acc: 0.215, val acc: 0.213
Epoch 090/100 – train acc: 0.218, val acc: 0.213
Epoch 100/100 – train acc: 0.220, val acc: 0.208
✓ mlp terminado. Test acc = 0.211


▶ Entrenando cnn …
Epoch 010/100 – train acc: 0.517, val acc: 0.385
Epoch 020/100 – train acc: 0.651, val acc: 0.480
Epoch 030/100 – train acc: 0.746, val acc: 0.509
Epoch 040/100 – train acc: 0.781, val acc: 0.535
Epoch 050/100 – train acc: 0.835, val acc: 0.541
Epoch 060/100 – train acc: 0.854, val acc: 0.565
Epoch 070/100 – train acc: 0.858, val acc: 0.573
Epoch 080/100 – train acc: 0.895, val acc: 0.569
Epoch 090/100 – train acc: 0.900, val acc: 0.585
Epoch 100/100 – train acc: 0.900, val acc: 0.588
✓ cnn terminado. Test acc = 0.525


▶ Entrenando eegnet …
Epoch 010/100 – train acc: 0.306, val acc: 0.235
Epoch 020/100 – train acc: 0.366, val acc: 0.225
Epoch 030/100 – train acc: 0.389, val acc: 0.268
Epoch 040/100 – train acc: 0.419, val acc: 0.272
Epoch 050/100 – train acc: 0.445, val acc: 0.297
Epoch 060/100 – train acc: 0.461, val acc: 0.269
Epoch 070/100 – train acc: 0.479, val acc: 0.272
Epoch 080/100 – train acc: 0.487, val acc: 0.279
Epoch 090/100 – train acc: 0.489, val acc: 0.273
Epoch 100/100 – train acc: 0.503, val acc: 0.293
✓ eegnet terminado. Test acc = 0.304


▶ Entrenando shallowconvnet …
Epoch 010/100 – train acc: 0.445, val acc: 0.303
Epoch 020/100 – train acc: 0.542, val acc: 0.288
Epoch 030/100 – train acc: 0.612, val acc: 0.319
Epoch 040/100 – train acc: 0.652, val acc: 0.307
Epoch 050/100 – train acc: 0.683, val acc: 0.329
Epoch 060/100 – train acc: 0.698, val acc: 0.297
Epoch 070/100 – train acc: 0.729, val acc: 0.316
Epoch 080/100 – train acc: 0.729, val acc: 0.296
Epoch 090/100 – train acc: 0.755, val acc: 0.303
Epoch 100/100 – train acc: 0.756, val acc: 0.316
✓ shallowconvnet terminado. Test acc = 0.360


▶ Entrenando deepconvnet …
Epoch 010/100 – train acc: 0.288, val acc: 0.232
Epoch 020/100 – train acc: 0.368, val acc: 0.252
Epoch 030/100 – train acc: 0.438, val acc: 0.304
Epoch 040/100 – train acc: 0.501, val acc: 0.316
Epoch 050/100 – train acc: 0.559, val acc: 0.336
Epoch 060/100 – train acc: 0.619, val acc: 0.328
Epoch 070/100 – train acc: 0.645, val acc: 0.356
Epoch 080/100 – train acc: 0.683, val acc: 0.372
Epoch 090/100 – train acc: 0.709, val acc: 0.356
Epoch 100/100 – train acc: 0.732, val acc: 0.372
✓ deepconvnet terminado. Test acc = 0.355


Benchmark completo → resultados en /media/beegfs/home/w314/w314139/PROJECT/silent-speech-decoding/experiments/otherModels_BCI_raw_ALL/benchmark_results.csv
