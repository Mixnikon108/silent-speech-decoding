[DATASET] Loading dataset from: BCI_processed.npz
[data] Cargando datos del dataset BCI
[INFO] Cargando datos desde: /media/beegfs/home/w314/w314139/PROJECT/silent-speech-decoding/data/processed/BCI2020/BCI_processed.npz
[INFO] Aplicando z-score normalization por trial
    - Forma de entrada (esperada): (trials, canales, muestras) = torch.Size([4500, 64, 795])
    - Calculando media y desviación estándar por trial
    - Mean shape: torch.Size([4500, 1, 1]), Std shape: torch.Size([4500, 1, 1])
    - Normalización completada. Forma de salida: torch.Size([4500, 64, 795])
[INFO] Padding aplicado: se añaden 5 valores a la derecha (dim original: 795)
[INFO] Dimensión temporal final: 800
[INFO] Aplicando z-score normalization por trial
    - Forma de entrada (esperada): (trials, canales, muestras) = torch.Size([750, 64, 795])
    - Calculando media y desviación estándar por trial
    - Mean shape: torch.Size([750, 1, 1]), Std shape: torch.Size([750, 1, 1])
    - Normalización completada. Forma de salida: torch.Size([750, 64, 795])
[INFO] Padding aplicado: se añaden 5 valores a la derecha (dim original: 795)
[INFO] Dimensión temporal final: 800
[INFO] Aplicando z-score normalization por trial
    - Forma de entrada (esperada): (trials, canales, muestras) = torch.Size([750, 64, 795])
    - Calculando media y desviación estándar por trial
    - Mean shape: torch.Size([750, 1, 1]), Std shape: torch.Size([750, 1, 1])
    - Normalización completada. Forma de salida: torch.Size([750, 64, 795])
[INFO] Padding aplicado: se añaden 5 valores a la derecha (dim original: 795)
[INFO] Dimensión temporal final: 800
[INFO] Cargando datos de todos los sujetos (concatenados)
[INFO] Dimensiones finales:
    - X_train: torch.Size([4500, 64, 800]), y_train: torch.Size([4500])
    - X_val:   torch.Size([750, 64, 800]), y_val:   torch.Size([750])
    - X_test:  torch.Size([750, 64, 800]), y_test:  torch.Size([750])
[INFO] Creando DataLoaders:
    - Batch size (train): 64  | Shuffle: True
    - Batch size (eval) : 32  | Shuffle: False
[INFO] Número de batches:
    - Train: 71 batches
    - Val  : 24 batches
    - Test : 24 batches

▶ Entrenando mlp …
Epoch 010/100 – train acc: 0.302, val acc: 0.201
Epoch 020/100 – train acc: 0.336, val acc: 0.199
Epoch 030/100 – train acc: 0.361, val acc: 0.200
Epoch 040/100 – train acc: 0.367, val acc: 0.197
Epoch 050/100 – train acc: 0.366, val acc: 0.197
Epoch 060/100 – train acc: 0.390, val acc: 0.209
Epoch 070/100 – train acc: 0.377, val acc: 0.207
Epoch 080/100 – train acc: 0.380, val acc: 0.208
Epoch 090/100 – train acc: 0.393, val acc: 0.205
Epoch 100/100 – train acc: 0.390, val acc: 0.205
✓ mlp terminado. Test acc = 0.201


▶ Entrenando cnn …
Epoch 010/100 – train acc: 0.262, val acc: 0.219
Epoch 020/100 – train acc: 0.331, val acc: 0.231
Epoch 030/100 – train acc: 0.399, val acc: 0.224
Epoch 040/100 – train acc: 0.464, val acc: 0.237
Epoch 050/100 – train acc: 0.512, val acc: 0.260
Epoch 060/100 – train acc: 0.575, val acc: 0.257
Epoch 070/100 – train acc: 0.622, val acc: 0.224
Epoch 080/100 – train acc: 0.648, val acc: 0.228
Epoch 090/100 – train acc: 0.684, val acc: 0.243
Epoch 100/100 – train acc: 0.729, val acc: 0.247
✓ cnn terminado. Test acc = 0.223


▶ Entrenando eegnet …
Epoch 010/100 – train acc: 0.328, val acc: 0.229
Epoch 020/100 – train acc: 0.400, val acc: 0.220
Epoch 030/100 – train acc: 0.442, val acc: 0.205
Epoch 040/100 – train acc: 0.480, val acc: 0.205
Epoch 050/100 – train acc: 0.501, val acc: 0.236
Epoch 060/100 – train acc: 0.524, val acc: 0.195
Epoch 070/100 – train acc: 0.544, val acc: 0.207
Epoch 080/100 – train acc: 0.563, val acc: 0.220
Epoch 090/100 – train acc: 0.580, val acc: 0.203
Epoch 100/100 – train acc: 0.579, val acc: 0.207
✓ eegnet terminado. Test acc = 0.213


▶ Entrenando shallowconvnet …
Epoch 010/100 – train acc: 0.399, val acc: 0.207
Epoch 020/100 – train acc: 0.518, val acc: 0.213
Epoch 030/100 – train acc: 0.588, val acc: 0.212
Epoch 040/100 – train acc: 0.632, val acc: 0.233
Epoch 050/100 – train acc: 0.686, val acc: 0.209
Epoch 060/100 – train acc: 0.709, val acc: 0.229
Epoch 070/100 – train acc: 0.722, val acc: 0.225
Epoch 080/100 – train acc: 0.755, val acc: 0.213
Epoch 090/100 – train acc: 0.762, val acc: 0.211
Epoch 100/100 – train acc: 0.778, val acc: 0.216
✓ shallowconvnet terminado. Test acc = 0.209


▶ Entrenando deepconvnet …
Epoch 010/100 – train acc: 0.331, val acc: 0.188
Epoch 020/100 – train acc: 0.481, val acc: 0.196
Epoch 030/100 – train acc: 0.609, val acc: 0.195
Epoch 040/100 – train acc: 0.713, val acc: 0.216
Epoch 050/100 – train acc: 0.784, val acc: 0.201
Epoch 060/100 – train acc: 0.805, val acc: 0.199
Epoch 070/100 – train acc: 0.844, val acc: 0.191
Epoch 080/100 – train acc: 0.859, val acc: 0.196
Epoch 090/100 – train acc: 0.877, val acc: 0.213
Epoch 100/100 – train acc: 0.882, val acc: 0.209
✓ deepconvnet terminado. Test acc = 0.225


Benchmark completo → resultados en /media/beegfs/home/w314/w314139/PROJECT/silent-speech-decoding/experiments/otherModels_BCI_processed_ALL/benchmark_results.csv
